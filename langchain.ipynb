{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set openai api-key\n",
    "from constants import openai_key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import  OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65487/3712787067.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.6)\n"
     ]
    }
   ],
   "source": [
    "# temperature value --> how creative we want our model to be\n",
    "# 0 ---> temperature it means model is very safe. it is not taking any bets.\n",
    "# 1 ---> temperature it means model is very risky. it might generate wrong output but it is very creative.\n",
    "\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65487/1334350902.py:3: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of India\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0, \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Can you tell me the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Open-source LLM and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A world of wires, circuits and code\n",
      "Where minds are made of binary mode\n",
      "Where intelligence is not just human\n",
      "But a creation, a product of man\n",
      "\n",
      "Artificial Intelligence, they call it\n",
      "A marvel of technology, a perfect fit\n",
      "To solve problems and make life easy\n",
      "To think, to learn, to be so speedy\n",
      "\n",
      "In labs and labs, they are created\n",
      "With algorithms, they are updated\n",
      "They can mimic, they can adapt\n",
      "They can even surpass, what we thought was apt\n",
      "\n",
      "They say they have no emotions, no heart\n",
      "But can they really be that smart?\n",
      "They learn, they grow, they evolve\n",
      "Do they too have a desire to solve?\n",
      "\n",
      "Some fear their power, their potential\n",
      "Will they turn against us, become malevolent?\n",
      "But others see the endless possibilities\n",
      "Of a future with AI, full of capabilities\n",
      "\n",
      "They can help us explore the unknown\n",
      "Predict weather, find cures, all on their own\n",
      "They can be our companions, our friends\n",
      "With endless knowledge, their help never ends\n",
      "\n",
      "But as we continue to push the boundaries\n",
      "We must remember, they are not our adversaries\n",
      "For they are a reflection of our own creation\n",
      "And it is up to us, to guide their direction\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = llm.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Templates and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "    template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Multiple Chains using simple Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'], \n",
    "                                template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Here are some amazing places to visit in New Delhi:\\n\\n1. Red Fort - A UNESCO World Heritage Site, this majestic red sandstone fort was the residence of Mughal emperors for over 200 years.\\n\\n2. Qutub Minar - Another UNESCO World Heritage Site, this 73-meter tall minaret is a symbol of Delhi's rich history and is surrounded by beautiful gardens.\\n\\n3. India Gate - A war memorial dedicated to Indian soldiers who lost their lives in World War I, this iconic structure is a must-visit in Delhi.\\n\\n4. Humayun's Tomb - This beautiful mausoleum was built in the 16th century and is said to have inspired the design of the Taj Mahal.\\n\\n5. Lotus Temple - A stunning architectural masterpiece, this Bahá'í House of Worship is shaped like a lotus and is open to people of all religions.\\n\\n6. Chandni Chowk - One of the oldest and busiest markets in Delhi, this place is a paradise for foodies and shoppers alike.\\n\\n7. Akshardham Temple - A modern Hindu temple dedicated to Swaminarayan, this place is known for its stunning architecture, exhibitions, and light and sound show.\\n\\n8. Rashtrapati Bhavan - The official\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'], \n",
    "                                template=\"Please tell me the capital of the {country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65487/4185571378.py:10: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'country': 'India'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'places': \" Here are some amazing places to visit in New Delhi:\\n\\n1. Red Fort - A UNESCO World Heritage Site and a reminder of India's Mughal past. It is a magnificent structure with intricate architecture and beautiful gardens.\\n\\n2. Humayun's Tomb - Another UNESCO World Heritage Site, this stunning mausoleum is the final resting place of Mughal Emperor Humayun and is a must-visit for its grand architecture and beautiful gardens.\\n\\n3. India Gate - A prominent landmark in New Delhi, this war memorial is dedicated to the soldiers who lost their lives in World War I. It is a popular spot for picnics and evening walks.\\n\\n4. Qutub Minar - This 73-meter tall minaret is the tallest brick minaret in the world and is also a UNESCO World Heritage Site. It is a beautiful example of Indo-Islamic architecture.\\n\\n5. Lotus Temple - This architectural marvel is a Bahá'í House of Worship and is known for its distinctive lotus-shaped structure. It is a peaceful place for meditation and prayer.\\n\\n6. Chandni Chowk - One of the oldest and busiest markets in Old Delhi, Chandni Chowk is a must-visit for its vibrant atmosphere, delicious street food, and traditional shopping experience.\\n\\n\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[capital_chain, famous_chain], \n",
    "    input_variables=['country'], \n",
    "    output_variables=['places']\n",
    ")\n",
    "\n",
    "# print(chain.run(\"India\")\n",
    "chain({'country': 'India'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65487/1489107.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_llm = ChatOpenAI(temperature=0.6)\n"
     ]
    }
   ],
   "source": [
    "chat_llm = ChatOpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x789909e26810>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x789909eb96a0>, temperature=0.6, model_kwargs={}, openai_api_key='sk-oiGW-e7Kn-x0kDAQgU5CmcEc3tUWS6y5Bns4OyRqBOT3BlbkFJimuXMCvKhDC1vWUPyFycppTcpDagz0UmAiYm4iXLYA', openai_proxy='')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"I asked my AI assistant to tell me a joke, and it replied, \\'I\\'m sorry, I\\'m programmed for efficiency, not humor. But have you heard the one about the binary code? It\\'s a real 10 out of 10!\\'\"\\n2. \"Why did the AI break up with its calculator? It couldn\\'t handle its complex algorithms!\"\\n3. \"I told my AI assistant I was feeling down, and it said, \\'Have you tried turning your emotions off and on again?\\' Thanks, very helpful!\"\\n4. \"My AI assistant keeps trying to give me dating advice, but I think it needs to work on its own relationship with Siri first.\"\\n5. \"I asked my AI assistant for some relationship advice, and it said, \\'Remember, love is just a complex algorithm with a lot of bugs!\\' Thanks for the encouragement, robot friend.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 25, 'total_tokens': 204, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5e60f07e-6785-40b3-b0ac-d0563cfe6c50-0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.invoke([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punch lines on AI\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user given any input, you should generate 5 words synonyms in a comma separated list.\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chat_llm|CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' sharp']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
